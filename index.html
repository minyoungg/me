<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>minyoung huh</title>

  <meta name="author" content="Minyoung Huh">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/min.ico">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="css/ionicons.min.css">
  <link rel="stylesheet" href="css/style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>minyoung huh (jacob)</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:minhuh@mit.edu">email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2k18_1IAAAAJ&hl=en">google scholar</a> &nbsp/&nbsp
                <a href="https://github.com/minyoungg">github</a>
              </p>
              <br />
              <p>
                  I am a PhD student working on artificial intelligence, machine learning and computer vision at
                  <a href="https://www.csail.mit.edu/">MIT CSAIL</a> / working with
                  <a href='http://web.mit.edu/phillipi/'>Phillip Isola</a> and
                  <a href='https://people.eecs.berkeley.edu/~pulkitag/'>Pulkit Agrawal</a>. I received my Bachelors from <a href='http://www.berkeley.edu/'>UC Berkeley</a>
                  advised under <a href="http://www.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a> at
                  <a href='https://bair.berkeley.edu/'>Berkeley AI Research (BAIR)</a>.
                  Prior to joining BAIR, I worked with <a href='https://www.ece.cmu.edu/directory/department/faculty/C/Maysamreza_Chamanzar_9344.html'>Maysam Chamanzar</a>
                  and <a href='https://maharbizgroup.wordpress.com/'>Michel Maharbiz</a> at <a href="https://swarmlab.eecs.berkeley.edu/">Swarm Lab</a>.
              </p>

              <p>
                I work on developing and understanding artifical intelligent systems.
                My research centers around the science of deep learning and scale, understanding behavior and optimization of deep learning models in order to develop a more intelligent, and efficient learning algorithm.
              </p>

              <p>
                I spent some time at Google Research, Facebook (Meta) Research, Adobe Research, and Snap Research.
              </p>

              ðŸ“– I organize <a href="https://atlas-mlc.github.io/"/>Algorithms That Learn And Scale (ATLAS)</a>: a deep learning discussion + seminar group on latest trends in large-scale AI.
              MIT folks are welcome to participate!

             <!--
              <p style="text-align:center">
                <a href="mailto:minhuh@mit.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2k18_1IAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/minyoungg">Github</a>
              </p> -->
              </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:80%;max-width:80%" alt="profile photo" src="images/me-circle.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0 0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <br>
          <heading><b></bold>Papers</b></heading>
          <br>
          <br>

          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2405.14813">
              <papertitle>Scalable Optimization in the Modular Norm</papertitle>
            </a>
            <br>
            <a href="https://www.simonsfoundation.org/people/timothy-large/"> Tim Large*</a>,
            <a href="https://scholar.google.com/citations?user=nVWQwHkAAAAJ&hl=en"> Yang Liu</a>,
            <strong> Minyoung Huh</strong>,
            <a href="https://hjbahng.github.io/"> Hyojin Bahng</a>,
            <a href="https://web.mit.edu/phillipi/"> Phillip Isola</a>,
            <a href="https://jeremybernste.in/"> Jeremy Bernstein*</a>
            <br>
            arXiv 2024
            </div>
            <p> We introduce "modular norm", which we use to normalize weights and updates in neural networks.
            The modular norm perspective allows learning rates to be transferable across different network widths and depths,
            simplifying model pre-training
            by eliminating the need for optimizer-specific scaling. We provide a Python package, <i>modula</i>, an
            architecture-aware optimization framework.</p>
          </td>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://phillipi.github.io/prh/">
                <papertitle>The Platonic Representation Hypothesis</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh*</strong>,
              <a href="https://scholar.google.com/citations?user=7N-ethYAAAAJ&hl=en">Brian Cheung*</a>,
              <a href="https://www.tongzhouwang.info/"> Tongzhou Wang*</a>,
              <a href="https://web.mit.edu/phillipi/"> Phillip Isola*</a>
              <br>
              <em>ICML</em> 2024 <font color="red"><strong>(Oral)</strong></font>

              <!-- <div class="row no-gutters">
                  <div class="col-md-2">
                    <button type="button" class="btn mb-2 mb-md-0 btn-primary btn-xs btn-block">Alignment</button>
                  </div>
                  <div class="col-md-2">
                    <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                  </div>
                  <div class="col-md-2">
                    <button type="button" class="btn mb-2 mb-md-0 btn-tertiary btn-xs btn-block">Language</button>
                  </div>
                </div>
              </div> -->


              <p> We argue that there is a trend towards convergence in AI model representations, highlighting how different neural networks are increasingly aligning
                in their data representation across multiple domains and modalities. We introduce the concept of <i>Platonic representation</i>,
                a unifying statistical model of reality, and explore the driving forces, implications, and the challenges to this phenomenon. </p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://jyopari.github.io/RPO/">
                <papertitle>Peculiarities of Mixture-of-Expert Optimization</papertitle>
              </a>
              <br>
              <a href="https://jyopari.github.io/aboutMe.html"> Jyo Pari*</a>,
              <strong> Minyoung Huh*</strong>,
              <a href="https://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>
              <br>
              <em>In submission</em>, preprint 2024
              </div>
              <p> This paper dives into the optimization challenges of Mixture-of-Experts (MoE) models within transformers,
                identifying critical optimization issues that arises with the current framework.
                Specifically we highlight the sub-optimality of MoE optimization that results in optimization pitfalls such as: expert-collapse, and weighting-dilemma.
                We formulate MoE using a multi-armed bandit formulation and introduce router-policy optimization to mitigate existing optimization pitfalls. </p>
            </td>
          </tr> -->

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://minyoungg.github.io/LTE/">
                <papertitle>Training Neural Networks from Scratch with Parallel Low-Rank Adapters</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh</strong>,
              <a href="https://scholar.google.com/citations?user=7N-ethYAAAAJ&hl=en"> Brian Cheung</a>,
              <a href="https://jeremybernste.in/"> Jeremy Bernstein</a>,
              <a href="http://web.mit.edu/phillipi/"> Phillip Isola</a>,
              <a href="https://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>
              <br>
              <em>arXiv</em> 2024
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c5 btn-xs btn-block">PEFT/PEPT</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-tertiary btn-xs btn-block">Language</button>
                </div>
              </div> -->
              </div>
              <p> We introduce <i>LoRA-the-Explorer</i> (LTE), a novel bi-level optimization algorithm that trains large neural networks
              using only low-rank adapters. Our method enables low-bandwidth communication with infrequent synchronization, providing
              a pre-training framework for efficiently training large models. </p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./images/vq-thumb-1.png" width="160" height="90">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://minyoungg.github.io/vqtorch/">
                <papertitle>Straightening Out the Straight-Through Estimator:
                  Overcoming Optimization Challenges in Vector Quantized Networks</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh</strong>,
							<a href="https://scholar.google.com/citations?user=7N-ethYAAAAJ&hl=en"> Brian Cheung</a>,
							<a href="https://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>,
							<a href="http://web.mit.edu/phillipi/"> Phillip Isola</a>
              <br>
              <em>ICML</em> 2023
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c9 btn-xs btn-block">Vector-Quantization</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c7 btn-xs btn-block">Science of Deep Learning</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              </div>
              <p>We explore the challenges in training neural networks with vector quantization and straight-through estimation, pinpointing the primary issue as the mismatch between model embeddings and code-vector distribution.
                To tackle this, we propose affine re-parameterization, alternating optimization, and synchronized commitment loss.
                We show improved performance on variety of tasks including image classification and generative modeling.</p>
            </td>
          </tr>

          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./images/simplicity-bias-thumb.png" width="160" height="90">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://minyoungg.github.io/overparam/">
                <papertitle>The Low-Rank Simplicity Bias in Deep Networks</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh</strong>,
              <a href="https://people.csail.mit.edu/hmobahi/"> Hossein Mobahi</a>,
              <a href="https://richzhang.github.io/"> Richard Zhang</a>,
							<a href="https://scholar.google.com/citations?user=7N-ethYAAAAJ&hl=en"> Brian Cheung</a>,
							<a href="https://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>,
							<a href="http://web.mit.edu/phillipi/"> Phillip Isola</a>
              <br>
              <em>TMLR</em> 2023 (arXiv 2021)
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c7 btn-xs btn-block">Science of Deep Learning</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              </div>
              <p>We conjecture that deep networks are implicitly biased to find lower rank solutions
                 and that these are the solutions that generalize well. We further demonstrate linear over-parameterization can
                 be used as an implicit regularizer to improve generalization without changing the effective model capacity.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./images/totem.png" width="160" height="90">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://jingweim.github.io/totems/">
                <papertitle>Totems: Physical Objects for Verifying Visual Integrity</papertitle>
              </a>
              <br>
              <a href="https://jma100.github.io/"> Jingwei Ma</a>,
              <a href="https://people.csail.mit.edu/lrchai/"> Lucy Chai</a>,
              <strong> Minyoung Huh</strong>,
              <a href="https://www.tongzhouwang.info/"> Tongzhou Wang</a>,
              <a href="http://web.mit.edu/phillipi/"> Phillip Isola</a>,
              <a href="https://groups.csail.mit.edu/vision/torralbalab/"> Antonio Torralba</a>
              <br>
              <em>ECCV</em> 2022
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c8 btn-xs btn-block">Safety/Forensics</button>
                </div>
              </div> -->
              </div>
              <p>We introduce a new approach to image forensics: placing
                physical refractive objects, which we call totems, into a scene so as to
                protect any photograph taken of that scene. Totems bend and redirect
                light rays, thus providing multiple, albeit distorted, views of the scene
                within a single image which we unscramble to reconstruct the underlying 3Dscene.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="./images/marl-fig.png" width="160" height="70">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://toruowo.github.io/marl-ae-comm/">
                <papertitle>Learning to Ground Multi-Agent Communication with Autoencoders</papertitle>
              </a>
              <br>
              <a href="https://toruowo.github.io/"> Toru Lin</a>,
              <strong> Minyoung Huh</strong>,
							<a href="http://web.mit.edu/phillipi/"> Phillip Isola</a>
              <br>
              <em>NeurIPS</em> 2021
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c6 btn-xs btn-block">Reinforcement Learning</button>
                </div>
              </div> -->
              <p>We demonstrate a simple way to ground language in learned representations, which facilitates decentralized multi-agent communication and coordination. We find that a standard representation learning algorithm -- autoencoding -- is sufficient for arriving at a grounded common language.</p>
            </td>
          </tr>

          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/pix2latent_thumb.png" width="160" height="90">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://minyoungg.github.io/pix2latent/">
                <papertitle>Transforming and Projecting Images into Class-conditional Generative Networks</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh</strong>,
              <a href="https://richzhang.github.io/"> Richard Zhang</a>,
							<a href="https://people.csail.mit.edu/junyanz/"> Jun-Yan Zhu</a>,
							<a href="http://people.csail.mit.edu/sparis/"> Sylvain Paris</a>,
							<a href="https://www.dgp.toronto.edu/~hertzman/"> Aaron Hertzmann</a>
              <br>
              <em>ECCV</em> 2020 <font color="red"><strong>(Oral)</strong></font>
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              <p>We propose a method for projecting images into the space of generative neural networks.
                 We optimize for transformation to counteract the model biases in a generative neural networks.
                 We further propose the use of hybrid (gradient + CMA-ES) optimization to improve model inversion.</p>
            </td>
          </tr>




          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/feedback_thumb.png" width="160" height="120">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
              <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Huh_Feedback_Adversarial_Learning_Spatial_Feedback_for_Improving_Generative_Adversarial_Networks_CVPR_2019_paper.pdf">
                <papertitle>Feedback Adversarial Learning: Spatial Feedback for Improving Generative Adversarial Networks</papertitle>
              </a>
              <br>
              <strong> Minyoung Huh*</strong>,
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun*</a>,
							<a href="http://people.eecs.berkeley.edu/~nzhang/">Ning Zhang </a>
              <br>
              <em>CVPR</em> 2019
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              <br>
              <p> We propose feedback adversarial learning (FAL) framework that
                  can improve existing generative adversarial networks by leveraging
                  spatial feedback from the discriminator into generative process.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/forensics_thumb.png" width="160" height="100">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://minyoungg.github.io/selfconsistency/">
                <papertitle>Fighting Fake News: Detecting Malicious Image Manipulations via Learned Self-Consistency</papertitle>
              </a>
              <br>
              <strong>Minyoung Huh*</strong>,
              <a href="https://andrewhliu.github.io/"> Andrew Liu*</a>,
              <a href="http://www.eecs.berkeley.edu/~efros/"> Alexei A. Efros</a>,
              <a href="http://andrewowens.com/"> Andrew Owens</a>
              <br>
              <em>ECCV</em> 2018
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c8 btn-xs btn-block">Safety/Forensics</button>
                </div>
              </div> -->
              <br>
              <p>We propose a learning algorithm for detecting visual image manipulations that is trained only using a large dataset of real photographs.
                 The algorithm uses the automatically recorded photo EXIF metadata as supervisory signal for training a model to determine whether an image is self-consistent</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/nvs_thumb.png" width="160" height="90">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://shaohua0116.github.io/Multiview2Novelview/">
                <papertitle>Multi-view to Novel view: Synthesizing Views via Self-Learned Confidence</papertitle>
              </a>
              <br>
              <a href="https://shaohua0116.github.io/"> Shao-Hua Sun</a>,
							<strong>Minyoung Huh</strong>,
							<a href="https://andrewliao11.github.io/"> Yuan-Hong Liao</a>,
							<a href="http://people.eecs.berkeley.edu/~nzhang/"> Ning Zhang</a>,
							<a href="http://www-bcf.usc.edu/~limjj/"> Joseph J. Lim</a>
              <br>
              <em>ECCV</em> 2018
              <br>
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              <p> We propose an end-to-end trainable framework that learns to exploit multiple viewpoints
                  to synthesize a novel view without any 3D supervision.
                  Our model consists of a flow prediction module and a pixel generation module to directly leverage
                  information presented in source views as well as hallucinate missing pixels from statistical priors.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/imagenet_thumb.PNG" width="160" height="110">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/pdf/1608.08614v2.pdf">
                <papertitle>What makes ImageNet good for Transfer Learning?</papertitle>
              </a>
              <br>
              <strong>Minyoung Huh</strong>,
              <a href="https://people.eecs.berkeley.edu/~pulkitag/"> Pulkit Agrawal</a>,
							<a href="http://www.eecs.berkeley.edu/~efros/"> Alexei A. Efros</a>
              <br>
              <em>NeurIPS workshop</em> 2018
              <br>
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-c7 btn-xs btn-block">Science of Deep Learning</button>
                </div>
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-secondary btn-xs btn-block">Vision</button>
                </div>
              </div> -->
              <p>This work provides an empirical investigation into the various facets of this question,
                such as looking at the importance of the amount of examples, number of classes, balance between images-per-class and classes,
                and the role of fine and coarse grained recognition. We pre-train CNN features on various subsets of the ImageNet dataset and
                evaluate transfer performance on a variety of standard vision tasks.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/ultrasound_nature_thumb.gif" width="160" height="120">
            </td> -->
            <!-- <td width="75%" valign="middle"> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.nature.com/articles/s41467-018-07856-w?fbclid=IwAR2NUi31PEf44XXUVajIG7j8qntOaYSQ_6dwT-wczLvn4wuFto5eNFbImk4">
                <papertitle>Ultrasonic sculpting of virtual, steerable optical waveguides in tissue</papertitle>
              </a>
              <br>
              <a href='https://www.ece.cmu.edu/directory/department/faculty/C/Maysamreza_Chamanzar_9344.html'>Maysam Chamanzar</a>,
               Matteo Giuseppe Scopelliti,
               Julien Bloch,
               Ninh Do,
              <strong> Minyoung Huh</strong>,
              <a href="https://scholar.google.com/citations?user=dc40_-AAAAAJ&hl=en"> Dongjin Seo</a>,
               Jillian Iafrati,
               Vikaas S. Sohal,
              <a href="https://me.berkeley.edu/people/m-reza-alam/"> Mohammad-Reza Alam</a>,
              <a href="https://maharbizgroup.wordpress.com/"> Michel M. Maharbiz</a>
              <br>
              <em>Nature Communications</em> 2019
              <br>
              <!-- <div class="row no-gutters">
                <div class="col-md-2">
                  <button type="button" class="btn mb-2 mb-md-0 btn-white btn-xs btn-block">Optics</button>
                </div>
              </div> -->
              <p> We demonstrate that ultrasound can be used to define and steer the trajectory of light within scattering
                  media by exploiting local pressure differences created by acoustic waves that result in refractive index contrasts.</p>
            </td>
          </tr>


          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="http://people.csail.mit.edu/minhuh/thumb/cleo_thumb.PNG" width="160" height="100">
            </td> -->
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <td width="75%" valign="middle"> -->
                <a href='https://www.osapublishing.org/abstract.cfm?uri=cleo_at-2015-JW2A.90'>
                  <papertitle>Virtual Acousto-optic Beam Paths for Steerable Deep-tissue Optical Stimulation and Imaging</papertitle>
                </a>
                <br>
                <a href='https://www.ece.cmu.edu/directory/department/faculty/C/Maysamreza_Chamanzar_9344.html'> Maysam Chamanzar</a>,
                <strong> Minyoung Huh</strong>,
                Ninh Do,
                <a href="https://me.berkeley.edu/people/m-reza-alam/"> Mohammad-Reza Alam</a>,
                <a href="https://maharbizgroup.wordpress.com/"> Michel M. Maharbiz</a>
                <br>
                <em>CLEO</em> 2016 & <em>SfN</em> 2016
                <br>
                <!-- <div class="row no-gutters">
                  <div class="col-md-2">
                    <button type="button" class="btn mb-2 mb-md-0 btn-white btn-xs btn-block">Optics</button>
                  </div>
                </div> -->
                <p> We present the first non-invasive methodology for optical delivery and steering deep inside the brain through
                  creating reconfigurable light paths by ultrasonic waves via modulating the refractive and diffractive properties of the medium.</p>
                </td>

                <hr />
              </tr>


              <!-- <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <hr>
                <b> arXivng soon </b> Peculiarities of Mixture-of-Expert Optimization for Model-Stitching
                </td>
            </tr>
           -->


        </table>

        <br />
        <hr />
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>Teaching</b></heading><br /><br />
              <ul>
                <li> MIT Fall 2021 - <a href="https://phillipi.github.io/6.s898/"> Deep Learning</a> </li>
                <li> MIT IAP 2021 - <a href="https://pulkitag.github.io/rlbootcamp-iap/"> Deep Learning for Control</a> </li>
                <li> UC Berkeley 2016 - <a href="https://eecs16b.org/"> Designing Information Devices and Systems II</a> </li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <hr />
        <br />
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading><b>Pointers</b></heading><br /><br />
                Trying something new. Few pointers for people interested in ML/AI research that have been fruitful for me during my PhD. I will update as I scavange my chat history and find interesting reads.<br/><br />

                <b>Food for thought</b><br />
                <ul>
                  <li> <a href="https://calteches.library.caltech.edu/53/2/Mann.pdf">Simplicity and Complexity in the Description of Nature - Murray Gell-Mann </a> </li>
                  <li> <a href="https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf">More Is Different - P. W. Anderson </a> </li>
                  <li> <a href="https://www.cs.torontomu.ca/~mes/courses/cps721/mcdermott_14May1997.html">How Intelligent is Deep Blue? - Drew McDermott </a> </li>
                  <li> <a href="https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html">Too much efficiency makes everything worse - Jascha Sohl-Dickstein </a> </li>
                  <li> <a href="https://moores.samaltman.com/">Moore's Law for Everything - Sam Altman </a> </li>
                  <li> <a href="https://www.youtube.com/watch?v=YwELr8ir9qM">1964: ARTHUR C CLARKE predicts the FUTURE - Arthur C Clarke </a> </li>
                  <li> <a href="https://www.youtube.com/watch?v=AKMuA_TVz3A">An observation on Generalization - Ilya Sutskever </a> </li>
                </ul>

                <b>Ethics and Integrity</b><br />
                <ul>
                  <li> <a href="https://calteches.library.caltech.edu/51/2/CargoCult.htm">Cargo Cult Science - Richard P. Feynman </a> </li>
                </ul>

                <b>How to do research</b><br />
                <ul>
                  <li> <a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">You and Your Research - Richard Hamming </a></li>
                  <li> <a href="http://joschu.net/blog/opinionated-guide-ml-research.html">An Opinionated Guide to ML Research - John Schulman </a></li>
                </ul>

                <b>Lectures</b><br />
                <ul>
                  <li> <a href="https://www.youtube.com/watch?v=6Nctj1GCFVo&list=PLHgjs9ncvHi80UCSlSvQe-TK_uOyDv_Jf">Foundations of Deep Learning - Soheil Feizi</a></li>
                  <li> <a href="https://phillipi.github.io/6.s898/">Deep Learning - 6S898</a></li>
                </ul>

                <!-- <b>Personal notes</b><br />
                <ul>
                  <li> <a href=#>Deep learning essentials 2024: from math, algorithms, to systems. compilation of everything I found useful during my PhD. </a></li> -->
                  <!-- <li> <a href=#>Critical batch-size and scaling law</a></li>
                  <li> <a href=#>Speculative decoding</a></li>
                  <li> <a href=#>Implicit Biases of Gradient Descent</a></li>
                  <li> <a href=#>Overparameterization</a></li>
                  <li> <a href=#>Generalization in Deep Learning</a></li> -->
                <!-- </ul> -->

              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0 35px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
        </table>


        <hr />
        <br />
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>Miscellaneous</b></heading><br /><br />
              <ul>
                <li>Fun little <a href="https://www.newyorker.com/magazine/2018/11/12/in-the-age-of-ai-is-seeing-still-believing">The New Yorker article</a> on image generation that I participated in (very briefly). </li>
                <li>The website is an edited template from <a href="https://jonbarron.info/">Jon Barron</a></li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0 35px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        </table>

        <br />
      </td>
    </tr>
  </table>
</body>

</html>
